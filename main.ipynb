{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the CSV file\n",
    "df = pd.read_csv('spam_emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type                                               Body\n",
      "0  ham  Hi Elvis Lazar     Your account has been creat...\n",
      "1  ham           http   www SmarterASP net img logo jp...\n",
      "2  ham           http   www SmarterASP net img logo jp...\n",
      "3  ham       New message  RJWFKVZSRPJMQKSB613MA7C        \n",
      "4  ham  New message  Hi  thanks for purchasing  Code  ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'Body'], dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nr rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type    0\n",
       "Body    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "#number of mussing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "def process_text(text):\n",
    "    #remove punctuation\n",
    "    #return a list of clean text words\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Hi, Elvis, Lazar, account, created, successfu...\n",
       "1    [http, www, SmarterASP, net, img, logo, jpg, E...\n",
       "3              [New, message, RJWFKVZSRPJMQKSB613MA7C]\n",
       "4     [New, message, Hi, thanks, purchasing, Code, IX]\n",
       "5                    [Attached, logo, image, facebook]\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the tokenization(lemas)\n",
    "df['Body'].head().apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a colletction of text to a matrix of tokens\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "mesages_bow = CountVectorizer(analyzer=process_text).fit_transform(df['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(mesages_bow, df['type'], test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217, 4862)\n"
     ]
    }
   ],
   "source": [
    "#shape of messages_bow\n",
    "print(mesages_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and train the Naive Bayes CLassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "#print the predictions\n",
    "print(classifier.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "#print the  actual values\n",
    "print(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.99      0.98       152\n",
      "        spam       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.97       173\n",
      "   macro avg       0.96      0.90      0.93       173\n",
      "weighted avg       0.97      0.97      0.97       173\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[151   1]\n",
      " [  4  17]]\n",
      "\n",
      "Accuracy:  0.9710982658959537\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_train)\n",
    "print(classification_report(y_train, pred))\n",
    "print()\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_train,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'spam' 'ham']\n",
      "['ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "#print the predictions\n",
    "print(classifier.predict(X_test))\n",
    "#print te actual values\n",
    "print(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.83      0.89        35\n",
      "        spam       0.57      0.89      0.70         9\n",
      "\n",
      "    accuracy                           0.84        44\n",
      "   macro avg       0.77      0.86      0.79        44\n",
      "weighted avg       0.89      0.84      0.85        44\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[29  6]\n",
      " [ 1  8]]\n",
      "\n",
      "Accuracy:  0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, pred))\n",
    "print()\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, pred))\n",
    "print()\n",
    "print('Accuracy: ', accuracy_score(y_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
